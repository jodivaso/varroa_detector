{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5420b912",
   "metadata": {},
   "source": [
    "# Training deep learning models for varroa mite detection\n",
    "\n",
    "This Jupyter notebook allows one to reproduce the results presented in the article \"Analysis of Varroa mite colony infestation level using new open software based on deep learning techniques\" by Jose Divasón, Ana Romero, Francisco Javier Martínez de Pisón, Miguel A. Silvestre, Pilar Santolaria and Jesús L. Yániz.\n",
    "\n",
    "### About the dataset\n",
    "\n",
    "Note that, before executing this Jupyter notebook, one has to download the dataset. It is available through Zenodo: https://zenodo.org/doi/10.5281/zenodo.10231844. \n",
    "\n",
    "Concretely, you can download it from:\n",
    "- Dataset + labels: https://zenodo.org/records/10231845/files/dataset.zip?download=1\n",
    "- CSV file for separating in training and validation sets: https://zenodo.org/records/10231845/files/df_dataset.csv?download=1\n",
    "\n",
    "If you do not want to apply deblurGAN techniques on your own, you can also download the dataset version with deblurGAN from: https://zenodo.org/records/10231845/files/images_deblurGAN.zip?download=1\n",
    "\n",
    "Unzip the dataset without changing the names. That is, the structure should be as follows:\n",
    "* dataset\n",
    "    * images\n",
    "    * labels\n",
    "    * images_deblurGAN\n",
    "* train_varroa_mite_detector.ipynb\n",
    "* rest of the ipynb and py files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047446e2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61e9eea-a6eb-4fe2-8f16-42a0eb80eaec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:02.186229Z",
     "start_time": "2022-12-14T18:34:02.171662Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os, random, time\n",
    "import cv2 as cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms \n",
    "from torchvision import io\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN, fasterrcnn_resnet50_fpn_v2, fasterrcnn_resnet50_fpn, fasterrcnn_mobilenet_v3_large_320_fpn\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "import torchvision.transforms.functional as F_vision\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "import timm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations.pytorch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from fasterrcnn_vitdet import create_VIT_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d3d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T16:19:55.888646Z",
     "start_time": "2022-11-30T16:19:55.885525Z"
    }
   },
   "source": [
    "## Training architecture and hyperparameters\n",
    "\n",
    "In this cell one can choose different models and combination of hyperparameters (crops, weights, threshold confidence, number of epochs, enable deblurGAN, batch size, ...).\n",
    "\n",
    "Please, note that the batch size should depend on the available GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa876fe5-a8c7-4233-b1b0-ab54d61d24de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:02.273470Z",
     "start_time": "2022-12-14T18:34:02.259153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# This is just the name of the output folder where the model will be saved\n",
    "currentNotebook = \"train_varroa_mite_detector.ipynb\"\n",
    "\n",
    "CROP_X, CROP_Y = 224, 224  # Crop size (ideally, it should be set as the input size of the backbone, but it is not mandatory)\n",
    "BACKBONE_NAME = \"resnet18_fpn\" # Backbone name\n",
    "WEIGHTS_BACKBONE = 'DEFAULT' \n",
    "THRESHOLD_CONFIDENCE = 0.50\n",
    "EARLY_STOP = 60 # Stop training if there is no improvement in EARLY_STOP consecutive epochs\n",
    "NUM_EPOCHS = 600 # Max number of epochs\n",
    "START_VALID_AT_EPOCH = 90 # Epoch to start validation\n",
    "DEBLURGAN = False # If deblurGAN is used or not.\n",
    "\n",
    "SEED = 42\n",
    "# Training parameters\n",
    "BATCH_TRAIN = 6\n",
    "SAMPLES_BY_EPOCH = 42 #64\n",
    "NUM_WORKERS = 0\n",
    "BATCH_VALID = 10\n",
    "BATCH_TEST = 20\n",
    "# Reduce LR on plateau technique\n",
    "LR = 0.01 #1e-5 #Learning rate\n",
    "FACTOR_REDUCE_ONPLATEAU = 0.75\n",
    "PATIENCE = 10\n",
    "\n",
    "bbox_params = A.BboxParams(format = 'pascal_voc',         \n",
    "         min_visibility = 0.6,\n",
    "         label_fields = ['labels'])\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3769b6e3",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b242be7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:02.287038Z",
     "start_time": "2022-12-14T18:34:02.279506Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f222b0f1-23a5-4a77-8757-6f8a351e2049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:02.304823Z",
     "start_time": "2022-12-14T18:34:02.291155Z"
    }
   },
   "outputs": [],
   "source": [
    "# To parse the annotations\n",
    "import xml.etree.ElementTree as ET\n",
    "import torchvision.transforms.functional as FT\n",
    "\n",
    "# Label map\n",
    "voc_labels = ('varroa', 'pupe')\n",
    "label_map = {k: v + 1 for v, k in enumerate(voc_labels)}\n",
    "label_map['background'] = 0\n",
    "rev_label_map = {v: k for k, v in label_map.items()}  # Inverse mapping\n",
    "\n",
    "def parse_annotation(annotation_path):\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    boxes = list()\n",
    "    labels = list()\n",
    "    difficulties = list()\n",
    "    for object in root.iter('object'):\n",
    "\n",
    "        difficult = int(object.find('difficult').text == '1')\n",
    "\n",
    "        label = object.find('name').text.lower().strip()\n",
    "        if label not in label_map:\n",
    "            continue\n",
    "\n",
    "        bbox = object.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text) - 1\n",
    "        ymin = int(bbox.find('ymin').text) - 1\n",
    "        xmax = int(bbox.find('xmax').text) - 1\n",
    "        ymax = int(bbox.find('ymax').text) - 1\n",
    "\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        labels.append(label_map[label])\n",
    "        difficulties.append(difficult)\n",
    "    return {'boxes': boxes, 'labels': labels, 'difficulties': difficulties}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d31a79c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:02.335583Z",
     "start_time": "2022-12-14T18:34:02.321420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use from jupyter notebook notebook\n",
    "from notebook import notebookapp\n",
    "import urllib\n",
    "import json\n",
    "import ipykernel\n",
    "from pathlib import Path\n",
    "\n",
    "def create_output_dir(display = True, create=True, dirbase = '../results'):\n",
    "    base_dir = Path(dirbase)\n",
    "    if not os.path.exists(base_dir) and create:\n",
    "        os.mkdir(base_dir)\n",
    "    dir_models = currentNotebook[:-6]\n",
    "    dir_models = dir_models.replace('.','_')\n",
    "    output_dir = base_dir / Path(dir_models) #settings[\"globals\"][\"output_dir\"])\n",
    "\n",
    "    if not os.path.exists(output_dir) and create:\n",
    "        os.mkdir(output_dir)\n",
    "        if display:\n",
    "            print(\"Directory \" , output_dir ,  \" Created \")\n",
    "    elif display:\n",
    "        print(\"Directory \" , output_dir ,  \" already exists\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212b836-d85b-484b-8e8c-76e261bdc894",
   "metadata": {},
   "source": [
    "## Create output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1cc370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:02.478600Z",
     "start_time": "2022-12-14T18:34:02.434393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  results/train_varroa_mite_detector  already exists\n",
      "results/train_varroa_mite_detector\n"
     ]
    }
   ],
   "source": [
    "output_dir = create_output_dir(display=True, create=True, dirbase = 'results/')\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e09eea",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d92995b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:02.517647Z",
     "start_time": "2022-12-14T18:34:02.482389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(807, 13)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('df_dataset.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af6c5bf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:02.632381Z",
     "start_time": "2022-12-14T18:34:02.604717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_image</th>\n",
       "      <th>name</th>\n",
       "      <th>file_boxes</th>\n",
       "      <th>pos_img</th>\n",
       "      <th>is_train</th>\n",
       "      <th>size_img_x</th>\n",
       "      <th>size_img_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/images/IMG_5993.jpg</td>\n",
       "      <td>IMG_5993</td>\n",
       "      <td>dataset/labels/IMG_5993.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>6048</td>\n",
       "      <td>8064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/images/IMG_5994.jpg</td>\n",
       "      <td>IMG_5994</td>\n",
       "      <td>dataset/labels/IMG_5994.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>6048</td>\n",
       "      <td>8064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/images/IMG_5700.jpg</td>\n",
       "      <td>IMG_5700</td>\n",
       "      <td>dataset/labels/IMG_5700.xml</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6048</td>\n",
       "      <td>8064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/images/IMG_5815.jpg</td>\n",
       "      <td>IMG_5815</td>\n",
       "      <td>dataset/labels/IMG_5815.xml</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>6048</td>\n",
       "      <td>8064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/images/IMG_5652.jpg</td>\n",
       "      <td>IMG_5652</td>\n",
       "      <td>dataset/labels/IMG_5652.xml</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>6048</td>\n",
       "      <td>8064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_image      name                   file_boxes  \\\n",
       "0  dataset/images/IMG_5993.jpg  IMG_5993  dataset/labels/IMG_5993.xml   \n",
       "1  dataset/images/IMG_5994.jpg  IMG_5994  dataset/labels/IMG_5994.xml   \n",
       "2  dataset/images/IMG_5700.jpg  IMG_5700  dataset/labels/IMG_5700.xml   \n",
       "3  dataset/images/IMG_5815.jpg  IMG_5815  dataset/labels/IMG_5815.xml   \n",
       "4  dataset/images/IMG_5652.jpg  IMG_5652  dataset/labels/IMG_5652.xml   \n",
       "\n",
       "   pos_img  is_train  size_img_x  size_img_y  \n",
       "0        0      True        6048        8064  \n",
       "1        1     False        6048        8064  \n",
       "2        2      True        6048        8064  \n",
       "3        3      True        6048        8064  \n",
       "4        4     False        6048        8064  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posic = df[['file_image', 'name', 'file_boxes', 'pos_img', 'is_train', 'size_img_x', 'size_img_y']].drop_duplicates().sort_values('pos_img').reset_index(drop=True)\n",
    "print(df_posic.shape)\n",
    "df_posic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2b78b",
   "metadata": {},
   "source": [
    "### Load the full dataset in RAM memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c6aef25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:10.037171Z",
     "start_time": "2022-12-14T18:34:02.635620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e746a0d24e1b4ad9a49b882d1f904d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rawpy\n",
    "import imageio\n",
    "from pathlib import Path\n",
    "\n",
    "lista_names_imagenes = df_posic['file_image'].values\n",
    "numero_imagen = dict(zip(lista_names_imagenes, np.arange(len(lista_names_imagenes))))\n",
    "df_posic['pos_img'] = df_posic['file_image'].map(numero_imagen)\n",
    "df['pos_img'] = df['file_image'].map(numero_imagen)\n",
    "\n",
    "list_imagenes = []\n",
    "list_boxes = []\n",
    "for idx in tqdm(df_posic.index):\n",
    "    df_img = df_posic.loc[idx]\n",
    "    file_image = df_img['file_image']\n",
    "    file_boxes = df_img['file_boxes'] \n",
    "    if DEBLURGAN:\n",
    "        file_image = \"dataset/images_deblurGAN/\"+Path(file_image).stem +\".jpg\"\n",
    "    image = cv2.imread(file_image)\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255.0              \n",
    "    list_imagenes.append(np.array(image))\n",
    "    file_image = df_img['file_image']\n",
    "    boxes = df.loc[df['file_image']==file_image, ['x_min', 'y_min', 'x_max', 'y_max']].values\n",
    "    list_boxes.append(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a5d17",
   "metadata": {},
   "source": [
    "### Tiling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b32e3fe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:34:11.583409Z",
     "start_time": "2022-12-14T18:34:10.038775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8064, 6048, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b683f3d1e0345b9a99a314b5d6c5a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(image.shape)\n",
    "valid_imagenes = []\n",
    "valid_boxes = []\n",
    "valid_labels = []\n",
    "valid_names = []\n",
    "positions=[] # For each sub-image, this saves its correspoindg position (x,y) in the full image.\n",
    "for nrow in tqdm(range(len(df_posic))):\n",
    "    row = df_posic.iloc[nrow]\n",
    "    if not row['is_train']:\n",
    "        pos_x, pos_y = 0, 0\n",
    "        size_img_x = row['size_img_x']\n",
    "        size_img_y = row['size_img_y']\n",
    "        image_orig = list_imagenes[nrow]\n",
    "        boxes_orig = list_boxes[nrow]\n",
    "        labels = torch.ones(len(boxes_orig), dtype=torch.int64)\n",
    "        while True:                \n",
    "            x_max = pos_x+CROP_X\n",
    "            y_max = pos_y+CROP_Y\n",
    "            if x_max>=size_img_x:                   \n",
    "                x_max = size_img_x\n",
    "            if y_max>=size_img_y:                  \n",
    "                y_max = size_img_y\n",
    "            transform = A.Compose([A.Crop(x_min = pos_x, y_min=pos_y, x_max=x_max, y_max=y_max), \n",
    "                           ToTensorV2()],\n",
    "                           bbox_params=bbox_params)\n",
    "            result_transform = transform(image=image_orig, bboxes=boxes_orig, labels=labels)\n",
    "            valid_imagenes.append(result_transform['image'])\n",
    "            valid_boxes.append(torch.as_tensor(result_transform['bboxes'], dtype=torch.float32))\n",
    "            valid_labels.append(torch.ones(len(result_transform['bboxes']), dtype=torch.int64))\n",
    "            valid_names.append(row['name'])\n",
    "            positions.append((pos_x, pos_y))\n",
    "            pos_x += CROP_X\n",
    "            if pos_x>=size_img_x:\n",
    "                pos_x = 0\n",
    "                pos_y += CROP_Y\n",
    "                # Sal\n",
    "                if pos_y >= size_img_y:\n",
    "                    break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee1589",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T16:20:38.710938Z",
     "start_time": "2022-11-30T16:20:38.708246Z"
    }
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf9e04d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T18:35:15.479360Z",
     "start_time": "2022-12-14T18:35:15.449401Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "    \n",
    "class varroa_dataloader(Dataset):\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, transforms=None, modo='train'):\n",
    "        super().__init__()\n",
    "        self.df = df        \n",
    "        self.transforms = transforms\n",
    "        self.modo = modo\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        if self.modo == 'train':\n",
    "            df_img = self.df.iloc[index]\n",
    "            pos_img = df_img['pos_img']\n",
    "            image = list_imagenes[pos_img].copy()\n",
    "            boxes = list_boxes[pos_img]\n",
    "            image_name = df_img['name']\n",
    "            # there is only one class\n",
    "            labels = torch.ones(len(boxes), dtype=torch.int64)\n",
    "\n",
    "            target = {}\n",
    "            target['image_id'] = torch.tensor([pos_img])\n",
    "\n",
    "            \n",
    "            transform = A.Compose([\n",
    "                A.RandomCrop(height=CROP_X, width=CROP_Y), \n",
    "                A.Rotate(),\n",
    "                A.HorizontalFlip(),\n",
    "                A.VerticalFlip(),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05),\n",
    "                ToTensorV2()], bbox_params=bbox_params)    \n",
    "            \n",
    "            # Balance between images with and without varroa mite during training (p=0.50)\n",
    "            result_transform = transform(image=image, bboxes=boxes, labels=labels)\n",
    "            if np.random.random()>0.50:\n",
    "                while len(result_transform['bboxes'])==0:\n",
    "                    result_transform = transform(image=image, bboxes=boxes, labels=labels)\n",
    "            else:\n",
    "                while len(result_transform['bboxes'])!=0:\n",
    "                    result_transform = transform(image=image, bboxes=boxes, labels=labels)\n",
    "                    \n",
    "            num_box = len(result_transform['bboxes'])\n",
    "            image = result_transform['image']\n",
    "            if num_box>0:\n",
    "                target['boxes'] = torch.as_tensor(result_transform['bboxes'], dtype=torch.float32)\n",
    "            else:\n",
    "                target['boxes'] = torch.as_tensor(torch.zeros((0,4), dtype=torch.float32))\n",
    "            target[\"labels\"] = torch.ones((num_box,), dtype=torch.int64)\n",
    "            target[\"area\"] = torch.as_tensor((boxes[:, 3] - boxes[:, 1])*(boxes[:, 2] - boxes[:, 0]))\n",
    "            target[\"iscrowd\"] = torch.zeros((num_box,), dtype=torch.int64)\n",
    "        \n",
    "        if self.modo == 'valid':\n",
    "            boxes = valid_boxes[index]\n",
    "            image = valid_imagenes[index]\n",
    "            labels = valid_labels[index]\n",
    "            if len(boxes)==0:\n",
    "                boxes = torch.as_tensor(torch.zeros((0,4), dtype=torch.float32))\n",
    "                labels = torch.ones((0,), dtype=torch.int64)\n",
    "            target = {}\n",
    "            num_box = len(boxes)\n",
    "            target['boxes'] = boxes\n",
    "            target['labels'] = labels\n",
    "            target['image_id'] = torch.tensor([index])\n",
    "            target[\"area\"] = torch.as_tensor((boxes[:, 3] - boxes[:, 1])*(boxes[:, 2] - boxes[:, 0]))\n",
    "            target[\"iscrowd\"] = torch.zeros((num_box,), dtype=torch.int64)\n",
    "            image_name = valid_names[index]\n",
    "        return image, target, image_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09886bd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T10:20:18.411686Z",
     "start_time": "2022-12-05T10:20:18.408994Z"
    }
   },
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a9cc5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T09:40:58.356009Z",
     "start_time": "2022-12-14T09:40:46.422086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_backbone(backbone_name, weights_backbone='DEFAULT'):\n",
    "    if backbone_name == 'resnet_18':\n",
    "        resnet_net = torchvision.models.resnet18(weights=weights_backbone)\n",
    "        modules = list(resnet_net.children())[:-2]\n",
    "        backbone = torch.nn.Sequential(*modules)\n",
    "        backbone.out_channels = 512\n",
    "\n",
    "    elif backbone_name == 'resnet_34':\n",
    "        resnet_net = torchvision.models.resnet34(weights=weights_backbone)\n",
    "        modules = list(resnet_net.children())[:-2]\n",
    "        backbone = torch.nn.Sequential(*modules)\n",
    "        backbone.out_channels = 512\n",
    "        \n",
    "    elif backbone_name == 'resnet_50':\n",
    "        resnet_net = torchvision.models.resnet50(weights=weights_backbone)\n",
    "        modules = list(resnet_net.children())[:-2]\n",
    "        backbone = torch.nn.Sequential(*modules)\n",
    "        backbone.out_channels = 2048\n",
    "\n",
    "    elif backbone_name == 'resnet_101':\n",
    "        resnet_net = torchvision.models.resnet101(weights=weights_backbone)\n",
    "        modules = list(resnet_net.children())[:-2]\n",
    "        backbone = torch.nn.Sequential(*modules)\n",
    "        backbone.out_channels = 2048\n",
    "\n",
    "    elif backbone_name == 'resnet_152':\n",
    "        resnet_net = torchvision.models.resnet152(weights=weights_backbone)\n",
    "        modules = list(resnet_net.children())[:-2]\n",
    "        backbone = torch.nn.Sequential(*modules)\n",
    "        backbone.out_channels = 2048\n",
    " \n",
    "    elif backbone_name == 'resnet_50_modified_stride_1':\n",
    "        resnet_net = resnet50(weights=weights_backbone)\n",
    "        modules = list(resnet_net.children())[:-2]\n",
    "        backbone = torch.nn.Sequential(*modules)\n",
    "        backbone.out_channels = 2048\n",
    "\n",
    "    elif backbone_name == 'resnext101_32x8d':\n",
    "        resnet_net = torchvision.models.resnext101_32x8d(weights=weights_backbone)\n",
    "        modules = list(resnet_net.children())[:-2]\n",
    "        backbone = torch.nn.Sequential(*modules)\n",
    "        backbone.out_channels = 2048\n",
    "    \n",
    "    elif backbone_name == \"regnet_y_400mf\":\n",
    "        model_backbone = torchvision.models.regnet_y_400mf(weights=weights_backbone)\n",
    "        backbone = torch.nn.Sequential(*list(model_backbone.children())[:-2])\n",
    "        backbone.out_channels = 440\n",
    "        \n",
    "    elif backbone_name == \"efficientnet_b0\":        \n",
    "        if weights_backbone == \"DEFAULT\": \n",
    "            weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "            backbone = torchvision.models.efficientnet_b0(weights=weights).features\n",
    "        else:\n",
    "            backbone = torchvision.models.efficientnet_b0().features \n",
    "        backbone.out_channels = 1280\n",
    "    \n",
    "    elif backbone_name == \"efficientnet_b1\":  \n",
    "        if weights_backbone == \"DEFAULT\": \n",
    "            weights = torchvision.models.EfficientNet_B1_Weights.DEFAULT\n",
    "            backbone = torchvision.models.efficientnet_b1(weights=weights).features\n",
    "        else:\n",
    "            backbone = torchvision.models.efficientnet_b1().features \n",
    "        backbone.out_channels = 1280\n",
    "    elif backbone_name == \"efficientnet_b2\":   \n",
    "        if weights_backbone == \"DEFAULT\": \n",
    "            weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "            backbone = torchvision.models.efficientnet_b2(weights=weights).features\n",
    "        else:\n",
    "            backbone = torchvision.models.efficientnet_b2().features \n",
    "        backbone.out_channels = 1408        \n",
    "    elif backbone_name == \"efficientnet_b3\":\n",
    "        if weights_backbone == \"DEFAULT\": \n",
    "            weights = torchvision.models.EfficientNet_B3_Weights.DEFAULT\n",
    "            backbone = torchvision.models.efficientnet_b3(weights=weights).features\n",
    "        else:\n",
    "            backbone = torchvision.models.efficientnet_b3().features         \n",
    "        backbone.out_channels = 1536\n",
    "    elif backbone_name == \"efficientnet_b4\":\n",
    "        if weights_backbone == \"DEFAULT\": \n",
    "            weights = torchvision.models.EfficientNet_B4_Weights.DEFAULT\n",
    "            backbone = torchvision.models.efficientnet_b4(weights=weights).features\n",
    "        else:\n",
    "            backbone = torchvision.models.efficientnet_b4().features     \n",
    "        backbone.out_channels = 1792\n",
    "    elif backbone_name == \"efficientnet_b5\":\n",
    "        if weights_backbone == \"DEFAULT\": \n",
    "            weights = torchvision.models.EfficientNet_B5_Weights.DEFAULT\n",
    "            backbone = torchvision.models.efficientnet_b5(weights=weights).features\n",
    "        else:\n",
    "            backbone = torchvision.models.efficientnet_b5().features         \n",
    "        backbone.out_channels = 2048\n",
    "    elif backbone_name == \"efficientnet_b6\":\n",
    "        if weights_backbone == \"DEFAULT\": \n",
    "            weights = torchvision.models.EfficientNet_B6_Weights.DEFAULT\n",
    "            backbone = torchvision.models.efficientnet_b6(weights=weights).features\n",
    "        else:\n",
    "            backbone = torchvision.models.efficientnet_b6().features         \n",
    "        backbone.out_channels = 2304\n",
    "    elif backbone_name == \"efficientnet_b7\":\n",
    "        if weights_backbone == \"DEFAULT\": \n",
    "            weights = torchvision.models.EfficientNet_B7_Weights.DEFAULT\n",
    "            backbone = torchvision.models.efficientnet_b7(weights=weights).features\n",
    "        else:\n",
    "            backbone = torchvision.models.efficientnet_b7().features \n",
    "        backbone.out_channels = 2560\n",
    "        \n",
    "    return backbone\n",
    "\n",
    "if BACKBONE_NAME == 'fasterrcnn_resnet50_fpn':\n",
    "    model = fasterrcnn_resnet50_fpn(num_classes=2) \n",
    "elif BACKBONE_NAME == \"vitdet\":\n",
    "    model = create_VIT_model(num_classes=2)\n",
    "# For fpn-based backbones, see: https://github.com/pytorch/vision/blob/main/torchvision/models/detection/backbone_utils.py\n",
    "# Possible values are 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', \n",
    "# 'resnext50_32x4d', 'resnext101_32x8d', 'wide_resnet50_2', 'wide_resnet101_2'\n",
    "elif BACKBONE_NAME.endswith(\"_fpn\"):  \n",
    "    BACKBONE_NAME = BACKBONE_NAME[:-4] # Drop the _fpn\n",
    "    backbone = resnet_fpn_backbone(backbone_name=BACKBONE_NAME, weights=WEIGHTS_BACKBONE)\n",
    "    model = FasterRCNN(backbone, num_classes=2)    \n",
    "else:\n",
    "    backbone = return_backbone(BACKBONE_NAME, WEIGHTS_BACKBONE)\n",
    "    anchor_generator = AnchorGenerator(sizes=((16,32,64, 128, 256),), \n",
    "                                        aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
    "                                                        output_size=7, sampling_ratio=2)\n",
    "    model = FasterRCNN(backbone, num_classes=2, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler)\n",
    "    \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb92f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:48:05.383223Z",
     "start_time": "2022-12-01T15:48:05.380033Z"
    }
   },
   "source": [
    "## Train/Val Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87ac6c12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T09:40:58.367466Z",
     "start_time": "2022-12-14T09:40:58.359753Z"
    }
   },
   "outputs": [],
   "source": [
    "class Averager:      ##Return the average loss \n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41213bfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T09:40:58.441656Z",
     "start_time": "2022-12-14T09:40:58.369792Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, scheduler, epoch, loss_obj='loss_objectness'):\n",
    "    model.train()\n",
    "    loss_classifier = Averager()\n",
    "    loss_box_reg = Averager()\n",
    "    loss_objectness = Averager()\n",
    "    loss_rpn_box_reg = Averager()\n",
    "    tqdm_bar = tqdm(loader)\n",
    "    for images, targets, image_ids in tqdm_bar:            \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)   ##Return the loss\n",
    "        \n",
    "        loss_classifier.send(loss_dict['loss_classifier'].item())  #Average out the loss\n",
    "        loss_box_reg.send(loss_dict['loss_box_reg'].item())  #Average out the loss\n",
    "        loss_objectness.send(loss_dict['loss_objectness'].item())  #Average out the loss\n",
    "        loss_rpn_box_reg.send(loss_dict['loss_rpn_box_reg'].item())  #Average out the loss\n",
    "        \n",
    "        losses = sum(loss for loss in loss_dict.values()) #loss_dict[loss_obj].values()\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tqdm_bar.set_description(f\"Train E:{epoch} - Loss:{loss_dict[loss_obj].item():0.4f}\")\n",
    "    tqdm_bar.close()\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss_classifier.value, loss_box_reg.value, loss_objectness.value, loss_rpn_box_reg.value\n",
    "\n",
    "def valid_epoch(model, loader):\n",
    "    model.eval()\n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\", iou_thresholds=[0.50])\n",
    "    seleccion_list = []\n",
    "    targets_list = []\n",
    "    for images, targets, image_name in tqdm(loader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)\n",
    "        for num_pred in range(len(images)):\n",
    "            pred_uniq = preds[num_pred]\n",
    "            cuales = pred_uniq['scores']> THRESHOLD_CONFIDENCE\n",
    "            seleccion = dict(boxes=pred_uniq['boxes'][cuales].float(),\n",
    "                             scores=pred_uniq['scores'][cuales].float(),\n",
    "                             labels=pred_uniq['labels'][cuales])\n",
    "            seleccion_list.append(seleccion)\n",
    "            targets_list.append(targets[num_pred])                    \n",
    "    all_images_preds = []            \n",
    "    for i, ((x,y), b) in enumerate(zip(positions, seleccion_list)):         \n",
    "        if (x,y) == (0,0): # New image\n",
    "            full_image_bboxes = []            \n",
    "            full_image_scores = []\n",
    "        if b['boxes'].numel() != 0:            \n",
    "            for (x_min, y_min, x_max, y_max) in b['boxes'].cpu().numpy():\n",
    "                full_image_bboxes.append((x_min + x , y_min + y,  x_max + x, y_max + y))            \n",
    "            aux_scores = []\n",
    "            for score in b['scores'].cpu().numpy():\n",
    "                full_image_scores.append(score)            \n",
    "        if i+1 == len(positions) or positions[i+1]==(0,0):\n",
    "            all_images_preds.append(dict(boxes=torch.tensor(full_image_bboxes), scores=torch.tensor(full_image_scores), labels=torch.tensor([1]*len(full_image_scores))))\n",
    "\n",
    "    # Real annotations (ground truth)\n",
    "    all_targets=[]\n",
    "    for nrow in tqdm(range(len(df_posic))):\n",
    "        row = df_posic.iloc[nrow]\n",
    "        if not row['is_train']:\n",
    "            a = parse_annotation(row['file_boxes'])\n",
    "            all_targets.append(dict(boxes=torch.tensor(a['boxes']),labels=torch.tensor(a['labels'])))\n",
    "                \n",
    "    metric.update(all_images_preds, all_targets)\n",
    "    metricas = metric.compute()\n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597fab8",
   "metadata": {},
   "source": [
    "## Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e11bc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T15:32:17.743175Z",
     "start_time": "2022-12-14T09:40:58.465268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b419200ae644b783f152a6dffd14bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.10561758452760321 [ 0.09000826054917914 0.02476246069584574 0.30455915204116274 0.0031404648242252214 ]\n",
      "Epoch=00 LR=0.01000000 min=0.1/0.1 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac05e8a36b0485ba13a6b4d2518463c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.05335484154056757 [ 0.10486388499183315 0.058472695627382824 0.04731254492487226 0.00277024061818208 ]\n",
      "Epoch=01 LR=0.01000000 min=0.2/0.3 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1a0c9ff9dd4d19a3e0c31d189009bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.0373574011443582 [ 0.05666079106075423 0.0558941164719207 0.03437674737402371 0.0024979496707341503 ]\n",
      "Epoch=02 LR=0.01000000 min=0.2/0.5 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad92d5b3552240729d63d089c40ed6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.03741548860645188 [ 0.056832353451422284 0.06620009749063424 0.023807055982095853 0.002822447501655136 ]\n",
      "Epoch=03 LR=0.01000000 min=0.2/0.7 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bdaf24b630429ebfcb75bc850f10c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.02848701334525166 [ 0.04743823009942259 0.047425808651106696 0.016466155648231506 0.002617858982245837 ]\n",
      "Epoch=04 LR=0.01000000 min=0.2/0.8 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e766680b0b2b471a866c8a88dc22395f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.019241351957524397 [ 0.028787184772746905 0.0334027408223067 0.012877819261380605 0.0018976629736633705 ]\n",
      "Epoch=05 LR=0.01000000 min=0.1/1.0 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94c98f7c22a40d8a5f98fd4bd93f426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.02382920861938536 [ 0.032665000430175235 0.04718231436397348 0.012819996702351741 0.002649522981040978 ]\n",
      "Epoch=06 LR=0.01000000 min=0.2/1.2 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d34b871005f4a61b698f79f74e5ed9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.02718536490907094 [ 0.038878529997808595 0.053407368649329455 0.013977105729281902 0.0024784552598638193 ]\n",
      "Epoch=07 LR=0.01000000 min=0.2/1.4 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d929e1341954560a9d05ec4b5d2de5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.026483453785268857 [ 0.034922591443838816 0.054562525025435855 0.01264394773170352 0.0038047509400972296 ]\n",
      "Epoch=08 LR=0.01000000 min=0.2/1.6 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3032edfe9de48ce808385b9ece815fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.027706270842047936 [ 0.04539698548614979 0.05342158967895167 0.009981683788022824 0.002024824415067477 ]\n",
      "Epoch=09 LR=0.01000000 min=0.3/1.9 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcdbbe6e3144c73b3ae7a7f1a351bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.028240554751911468 [ 0.04075551897819553 0.05615568320666041 0.01315432381150978 0.0028966930112801492 ]\n",
      "Epoch=10 LR=0.01000000 min=0.3/2.3 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c062826b914ecb88aa8bb7b13da863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.027477828371047508 [ 0.0462259440017598 0.04876852833798954 0.012563549647373813 0.0023532914970668833 ]\n",
      "Epoch=11 LR=0.01000000 min=0.3/2.6 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce0a606f1834ffe90cdeb4c15ca9018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.02409028102868303 [ 0.03451697288879326 0.050957903265953064 0.0087884979854737 0.002097749974512096 ]\n",
      "Epoch=12 LR=0.01000000 min=0.3/2.9 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae63a04b4c24d6e82f0da42b5207a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.023915012527530574 [ 0.032869967365903516 0.04859990120998451 0.011375106605035918 0.00281507492919835 ]\n",
      "Epoch=13 LR=0.01000000 min=0.3/3.2 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe224e4f46c44bbb96e5ec3f89309a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.0229837648886522 [ 0.02885410681899105 0.05061797824289117 0.01034968625754118 0.0021132882351854016 ]\n",
      "Epoch=14 LR=0.01000000 min=0.3/3.5 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6c849acfed4c959ab768d922856fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.025240340552824946 [ 0.03530736440526588 0.05192537432802575 0.010155593843332358 0.0035730296346758094 ]\n",
      "Epoch=15 LR=0.01000000 min=0.2/3.6 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7f2f733d744aeea1166958eaf02898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.024146883316071968 [ 0.030843390950134823 0.05490754118987492 0.008226568211934395 0.0026100329123437405 ]\n",
      "Epoch=16 LR=0.01000000 min=0.2/3.9 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdbbb294704434c9e1bd8593b338062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.022298034919783407 [ 0.0306672961118498 0.04835241234728268 0.0073764756255384 0.0027959555944627418 ]\n",
      "Epoch=17 LR=0.01000000 min=0.3/4.2 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6060888302854007abac3c940f2d5c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.024347012978978455 [ 0.035611379093357494 0.053325611033609936 0.007120123964601329 0.0013309378243450607 ]\n",
      "Epoch=18 LR=0.01000000 min=0.3/4.5 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1227e020b5a400b880ee708ec23af7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.028363605433176935 [ 0.03853653557598591 0.0620160877172436 0.010443715511688165 0.0024580829277900712 ]\n",
      "Epoch=19 LR=0.01000000 min=0.2/4.7 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a962359c574792b9134c645803e7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN= 0.024452639318561915 [ 0.03517950206462826 0.05034496236060347 0.009582265446494733 0.002703827402521191 ]\n",
      "Epoch=20 LR=0.01000000 min=0.2/4.9 map_50=-0.010\n",
      "[]\n",
      "BestE=00 map_50=-0.010\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf13a82b5c7c4e819559b33d44cbc4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                       factor=FACTOR_REDUCE_ONPLATEAU, patience=PATIENCE)\n",
    "\n",
    "validset = varroa_dataloader(df = pd.DataFrame({'name':valid_names}), modo='valid')\n",
    "valid_data_loader = DataLoader(validset, batch_size=BATCH_VALID, shuffle=False, drop_last=False, \n",
    "                           num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "\n",
    "start = time.time()\n",
    "map_metric = -0.01\n",
    "best_map_metric = -0.01\n",
    "map_50 = -0.01\n",
    "best_map_50 = -0.01\n",
    "map_75 = -0.01\n",
    "best_map_75 = -0.01\n",
    "mar_1 = -0.01\n",
    "best_mar_1 = -0.01\n",
    "mar_10 = -0.01\n",
    "best_mar_10 = -0.01\n",
    "mar_100 = -0.01\n",
    "best_mar_100 = -0.01\n",
    "\n",
    "best_epoch = 0\n",
    "early_stop_count = 0\n",
    "obj_metric = 'map_50'\n",
    "metricas = []\n",
    "best_metricas = []\n",
    "res = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    seed_everything(SEED*(epoch+1))\n",
    "    trainset = varroa_dataloader(df = df[df.is_train].sample(SAMPLES_BY_EPOCH, replace=False), modo='train')\n",
    "    train_data_loader = DataLoader(trainset, batch_size=BATCH_TRAIN, shuffle=True, drop_last=False, collate_fn=collate_fn)\n",
    "    #                                num_workers=NUM_WORKERS, \n",
    "    start_epoch = time.time()\n",
    "    \n",
    "    if scheduler.__class__ ==  torch.optim.lr_scheduler.OneCycleLR:\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "    else:\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    loss_classifier, loss_box_reg, loss_objectness, loss_rpn_box_reg = train_epoch(model, train_data_loader,  \n",
    "                                                                               optimizer, scheduler, epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "    print('MEAN=', np.mean(np.array([loss_classifier, loss_box_reg, loss_objectness, loss_rpn_box_reg])), \n",
    "          '[',loss_classifier, loss_box_reg, loss_objectness, loss_rpn_box_reg, ']')\n",
    "    \n",
    "    # During the first epochs do not perform validation or update the scheduler.\n",
    "    # --------------------------------------------------------------\n",
    "    if epoch > START_VALID_AT_EPOCH:\n",
    "        # Validation\n",
    "        metricas = valid_epoch(model, valid_data_loader)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Save best model\n",
    "        map_metric = metricas[obj_metric].item()\n",
    "        map_50 = metricas['map_50'].item()\n",
    "        map_75 = metricas['map_75'].item()\n",
    "        \n",
    "        mar_1 = metricas['mar_1'].item()\n",
    "        mar_10 = metricas['mar_10'].item()\n",
    "        mar_100 = metricas['mar_100'].item()\n",
    "\n",
    "        if map_metric > best_map_metric:\n",
    "            print(f\"########## >>>>>>>> Model Improved {obj_metric} From {best_map_metric} to {map_metric}\")\n",
    "            torch.save(model.state_dict(), output_dir / f'modelo.bin')\n",
    "            best_map_metric = map_metric\n",
    "            best_epoch = epoch\n",
    "            early_stop_count = 0\n",
    "            best_metricas = metricas\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "            if early_stop_count>=EARLY_STOP:\n",
    "                break\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(map_metric)\n",
    "\n",
    "\n",
    "    tiempo = round(((time.time() - start)/60),2)\n",
    "    tiempo_epoch = round(((time.time() - start_epoch)/60),2)\n",
    "    #             clear_output(wait=True) #to clean warnings\n",
    "    print(f'Epoch={epoch:02d} LR={lr:0.08f} min={tiempo_epoch:.01f}/{tiempo:.01f} {obj_metric}={map_metric:.03f}\\n{metricas}')\n",
    "    print(f'BestE={best_epoch:02d} {obj_metric}={best_map_metric:.03f}\\n{best_metricas}')\n",
    "    res.append(dict({'epoch':epoch, 'lr':lr, 'tiempo':tiempo,\n",
    "                     'map_metric':map_metric, 'best_map_metric':best_map_metric, \n",
    "                     'map_50': map_50, 'map_75': map_75, \n",
    "                     'mar_1': mar_1, 'mar_10': mar_10, 'mar_100': mar_100\n",
    "                     }))\n",
    "    res_df = pd.DataFrame(res)\n",
    "    res_df.to_csv(output_dir / f'modelo_res.csv')\n",
    "\n",
    "    # Draw curves if not in console\n",
    "    # -----------------------------\n",
    "    fig, axs = plt.subplots(2,2, figsize=(15,15))\n",
    "\n",
    "    axs[1,0].plot(res_df['map_metric'].values, label='map')\n",
    "    axs[1,0].set_xlabel('Epochs')\n",
    "    axs[1,0].set_ylabel('MAP')\n",
    "    axs[1,0].set_title(f'MAP={map_metric:.4f} BestMap={best_map_metric:.4f} in Epoch{best_epoch}')\n",
    "\n",
    "    axs[0,0].plot(res_df['map_50'].values, label='map_50')\n",
    "    axs[0,0].plot(res_df['map_75'].values, label='map_75')\n",
    "    axs[0,0].set_xlabel('Epochs')\n",
    "    axs[0,0].set_ylabel('MAPS')\n",
    "    axs[0,0].set_title(f'map_50={map_50:.4f}({np.max(res_df[\"map_50\"].values):.4f}) map_75={map_75:.4f}({np.max(res_df[\"map_75\"].values):.4f})')\n",
    "\n",
    "    axs[0,1].plot(res_df['mar_10'].values, label='mar_10')\n",
    "    axs[0,1].plot(res_df['mar_100'].values, label='mar_100')\n",
    "\n",
    "    axs[0,1].set_xlabel('Epochs')\n",
    "    axs[0,1].set_ylabel('MARS')\n",
    "    axs[0,1].set_title(f'mar_10={mar_10:.4f}({np.max(res_df[\"mar_10\"].values):.4f}) mar_100={mar_100:.4f}({np.max(res_df[\"mar_100\"].values):.4f})')\n",
    "    \n",
    "    axs[1,1].plot(res_df['lr'].values)\n",
    "    axs[1,1].set_xlabel('Epochs')\n",
    "    axs[1,1].set_ylabel('Learning Rate')\n",
    "    axs[1,1].set_title(f'Learning Rate={lr:.8f} Max={res_df.lr.max():.8f} Min={res_df.lr.min():.8f}')\n",
    "    fig.savefig(output_dir / f'modelo_errors.png',facecolor='white', edgecolor='white')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb2af16",
   "metadata": {},
   "source": [
    "**Once here, the training is over!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206120e-1483-4a15-aa47-a1add33e50d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "775px",
    "left": "26px",
    "top": "89px",
    "width": "263.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
